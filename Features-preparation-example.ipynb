{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a2f446-949e-4378-8768-8beecb1d487c",
   "metadata": {},
   "source": [
    "# Preparing Data for Apache Spark ML Model\n",
    "\n",
    "## Preparing the environment\n",
    "\n",
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3b3364f-3d06-47e2-9ecd-a1a7f8358b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import (StringIndexer, OneHotEncoder, VectorAssembler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e8878d-3bbc-4fd9-9117-f7f9e6f79e0b",
   "metadata": {},
   "source": [
    "### Spark Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7efbeeb5-b315-429c-8fb9-c0f08250693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# eval DataFrame in notebooks\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "# activate gpu\n",
    "spark.conf.set(\"spark.driver.resource.gpu.amount\",\"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2242e852-0edd-46b2-87e1-55edeaafed81",
   "metadata": {},
   "source": [
    "## Scenario 1: VectorAssembler: numerical features\n",
    "\n",
    "Let's start with a VectorAssembler when only numerical features are available in the data. Below code creates a spark dataframe `customerdata` with three columns: `cust_id`, `monthly_payment` and `tenure_yrs`. Both `monthly_payment` and `tenure_yrs` are numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d29dda24-87dc-47b7-b48f-321745caebf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+----------+\n",
      "|cust_id|monthly_payment|tenure_yrs|\n",
      "+-------+---------------+----------+\n",
      "|      1|          29.99|         5|\n",
      "|      2|          31.99|         3|\n",
      "|      3|          24.99|         1|\n",
      "|      4|          21.99|         3|\n",
      "+-------+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customerdata = spark.createDataFrame([(1, 29.99, 5),\n",
    "                                      (2, 31.99, 3),\n",
    "                                      (3, 24.99, 1),\n",
    "                                      (4, 21.99, 3),\n",
    "                                     ], ['cust_id', 'monthly_payment', 'tenure_yrs'])\n",
    "customerdata.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "053758b6-c956-4a75-a7e1-638a569a9d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+----------+-----------+\n",
      "|cust_id|monthly_payment|tenure_yrs|features   |\n",
      "+-------+---------------+----------+-----------+\n",
      "|1      |29.99          |5         |[29.99,5.0]|\n",
      "|2      |31.99          |3         |[31.99,3.0]|\n",
      "|3      |24.99          |1         |[24.99,1.0]|\n",
      "|4      |21.99          |3         |[21.99,3.0]|\n",
      "+-------+---------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The VectorAssembler combines all the variables into one column. Let’s call it ‘features’ as shown below.\n",
    "assembler = VectorAssembler(inputCols=[\"monthly_payment\", \"tenure_yrs\"],\n",
    "                            outputCol=\"features\")\n",
    "outdata = assembler.transform(customerdata)\n",
    "outdata.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d06d58-62f2-41f7-9d40-05d5e11c685d",
   "metadata": {},
   "source": [
    "## Scenario 2: VectorAssembler: numerical + categorical features\n",
    "\n",
    "Below, I have created a spark dataframe `customerdata1` consisting of numerical (`monthly_payment` and `tenure_yrs`) and a categorical (`state`) variables. The state variable contains 3 types: `MD`, `VA` and `WA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0b194e6-055d-4377-a208-3039b70b3898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+----------+-----+\n",
      "|cust_id|monthly_payment|tenure_yrs|state|\n",
      "+-------+---------------+----------+-----+\n",
      "|1      |29.99          |5         |MD   |\n",
      "|2      |31.99          |3         |MD   |\n",
      "|3      |24.99          |1         |VA   |\n",
      "|4      |21.99          |3         |WA   |\n",
      "|5      |22.0           |3         |WA   |\n",
      "|6      |25.0           |7         |WA   |\n",
      "+-------+---------------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customerdata1 = spark.createDataFrame([(1, 29.99, 5, 'MD'),\n",
    "                                       (2, 31.99, 3, 'MD'),\n",
    "                                       (3, 24.99, 1, 'VA'),\n",
    "                                       (4, 21.99, 3, 'WA'),\n",
    "                                       (5, 22.00, 3, 'WA'),\n",
    "                                       (6, 25.00, 7, 'WA'),\n",
    "                                      ], ['cust_id', 'monthly_payment', 'tenure_yrs', 'state']\n",
    ")\n",
    "customerdata1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38581423-8f70-4dca-a8a9-72551c5b6b70",
   "metadata": {},
   "source": [
    "There is a little bit more work involved when we have categorical variable in the data. First step here, is to change categories to number, which is accomplished by using `StringIndexer` available in `pyspark.ml.feature`. The `StringIndexer` assigns unique values to each of the categories of a variable.\r\n",
    "\r\n",
    "Whe`n StringIndex`er is applied, the most frequent category gets the inde`x` 0, followed b`y` 1 for the next most frequent category and so on. Below, stae `: `WA get`s` 0 index as it is the most frequent category i`n sta`te, followed b`y `D` `:1 an`d `A` `:2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bd4328a-7c04-4347-be28-32aee6bb4849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+----------+-----+--------+\n",
      "|cust_id|monthly_payment|tenure_yrs|state|stateNum|\n",
      "+-------+---------------+----------+-----+--------+\n",
      "|1      |29.99          |5         |MD   |1.0     |\n",
      "|2      |31.99          |3         |MD   |1.0     |\n",
      "|3      |24.99          |1         |VA   |2.0     |\n",
      "|4      |21.99          |3         |WA   |0.0     |\n",
      "|5      |22.0           |3         |WA   |0.0     |\n",
      "|6      |25.0           |7         |WA   |0.0     |\n",
      "+-------+---------------+----------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol='state', outputCol='stateNum')\n",
    "indexd_data=indexer.fit(customerdata1).transform(customerdata1)\n",
    "indexd_data.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4de7d30-2b8e-47ce-8574-455dfcb26919",
   "metadata": {},
   "source": [
    "Next, we use `OneHotEncoder` to encode the indexed variable (`stateNum`) and finally use `VectorAssembler` to assemble all numerical and one hot encoded vectors together. Output from `OneHotEncoder` (`stateVec`) is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e5fc4b6-2de1-4e6a-ba33-417a9596c5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+----------+-----+--------+-------------+\n",
      "|cust_id|monthly_payment|tenure_yrs|state|stateNum|stateVec     |\n",
      "+-------+---------------+----------+-----+--------+-------------+\n",
      "|1      |29.99          |5         |MD   |1.0     |(2,[1],[1.0])|\n",
      "|2      |31.99          |3         |MD   |1.0     |(2,[1],[1.0])|\n",
      "|3      |24.99          |1         |VA   |2.0     |(2,[],[])    |\n",
      "|4      |21.99          |3         |WA   |0.0     |(2,[0],[1.0])|\n",
      "|5      |22.0           |3         |WA   |0.0     |(2,[0],[1.0])|\n",
      "|6      |25.0           |7         |WA   |0.0     |(2,[0],[1.0])|\n",
      "+-------+---------------+----------+-----+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(inputCol='stateNum', outputCol = 'stateVec')\n",
    "onehotdata = encoder.fit(indexd_data).transform(indexd_data)\n",
    "onehotdata.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9893a556-b7a5-4b1c-aa5f-ad64f754d914",
   "metadata": {},
   "source": [
    "Now, that we have converted the categorical feature to numerical form, we need to assemble all the input columns including this converted one into a single vector called `features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4a193ec-77e0-4f0f-9926-0a75d6bdd5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+----------+-----+--------+-------------+-----------------------+\n",
      "|cust_id|monthly_payment|tenure_yrs|state|stateNum|stateVec     |features               |\n",
      "+-------+---------------+----------+-----+--------+-------------+-----------------------+\n",
      "|1      |29.99          |5         |MD   |1.0     |(2,[1],[1.0])|[1.0,29.99,5.0,0.0,1.0]|\n",
      "|2      |31.99          |3         |MD   |1.0     |(2,[1],[1.0])|[2.0,31.99,3.0,0.0,1.0]|\n",
      "|3      |24.99          |1         |VA   |2.0     |(2,[],[])    |[3.0,24.99,1.0,0.0,0.0]|\n",
      "|4      |21.99          |3         |WA   |0.0     |(2,[0],[1.0])|[4.0,21.99,3.0,1.0,0.0]|\n",
      "|5      |22.0           |3         |WA   |0.0     |(2,[0],[1.0])|[5.0,22.0,3.0,1.0,0.0] |\n",
      "|6      |25.0           |7         |WA   |0.0     |(2,[0],[1.0])|[6.0,25.0,7.0,1.0,0.0] |\n",
      "+-------+---------------+----------+-----+--------+-------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler1 = VectorAssembler(\n",
    "    inputCols=['cust_id', 'monthly_payment', 'tenure_yrs', 'stateVec'],\n",
    "    outputCol='features')\n",
    "outdata1 = assembler1.transform(onehotdata)\n",
    "outdata1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b00d7-90bd-493a-9692-eb2e80111b75",
   "metadata": {},
   "source": [
    "[Source](https://medium.com/@statistics.sudip/preparing-data-for-apache-spark-ml-model-4fedcc31a0f4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
